{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import time\n",
    "# create a browser instance\n",
    "from selenium import webdriver\n",
    "# emulate keyboard inputs\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# creatinga single browser instance\n",
    "import selenium.webdriver.firefox.service as service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "# WebDriverWait and EC to allow waiting for element to load on page\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# module to search for elements using xpaths\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "# exception handling\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "# quick clicking and scrolling\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "# searching of html with \"find()\"\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import os                       # file saving\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Selenium Bot Class - make sure that \"chromedriver\" and \"geckodriver\" are in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class selenium_bot():\n",
    "    \"\"\"\n",
    "    Interactable bot, that parses outlook files\n",
    "    \"\"\"\n",
    "    def __init__(self, browser, timeout, save_period, url, succesful_login_xpath):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] browser: \"Firefox\" or \"Chrome\"\n",
    "        [float] timeout: how long to wait for responses from webpage\n",
    "        [save_period] float: time in seconds to create backup of parsed data\n",
    "        [str] url: url bot starts off at\n",
    "        [str] succesful_login_xpath: xpath to indicate that page has loaded\n",
    "\n",
    "        __ Description __\n",
    "        sets up selenium bot\n",
    "        \"\"\"\n",
    "\n",
    "        self.browser = browser.lower()\n",
    "        self.timeout = timeout\n",
    "        self.url = url\n",
    "        self.succesful_login_xpath = succesful_login_xpath\n",
    "        \n",
    "        # 1 - setup browser\n",
    "        self.driver = self.__setup_chrome()\n",
    "        self.driver.maximize_window()\n",
    "\n",
    "        # 2 - load page\n",
    "        self.driver.get(self.url)\n",
    "\n",
    "        # 3- supprorting parameters for the future\n",
    "        # waiter, to wait for contents to load. call the \"waiter.until(function)\" method\n",
    "        self.WebDriverWaiter = WebDriverWait(self.driver, self.timeout)\n",
    "        self.save_period = save_period\n",
    "        \n",
    "        print(\"==> setup_browser end\\n\")\n",
    "\n",
    "    def __setup_firefox(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        open up a firefox driver\n",
    "\n",
    "        __ Returns __\n",
    "        driver handle\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - create a browser instance\n",
    "        print(\"  > Starting new Firefox server\")\n",
    "        browser = webdriver.Firefox(\n",
    "            executable_path='./geckodriver')\n",
    "\n",
    "        return browser\n",
    "\n",
    "    def __setup_chrome(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        open up a chrome driver\n",
    "\n",
    "        __ Returns __\n",
    "        driver handle\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - set capabilities\n",
    "        capabilities = {'chromeOptions':\n",
    "                        {\n",
    "                            'useAutomationExtension': False,\n",
    "                            'args': ['--disable-extensions']}\n",
    "                        }\n",
    "\n",
    "        # 2 - set options for chrome\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_experimental_option(\"prefs\", {\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True\n",
    "        })\n",
    "\n",
    "        # 3 - create a browser instance with defined options\n",
    "        print(\"  > Starting new Chrome server\")\n",
    "        browser = webdriver.Chrome(executable_path=\"./chromedriver\",\n",
    "                                   desired_capabilities=capabilities,\n",
    "                                   options=chrome_options)\n",
    "        return browser\n",
    "    \n",
    "    def supp_extract_html(self, soup, html_tags_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [soup] soup: html to extract from formatted with BeautifulSoup\n",
    "        [arr] html_tags_array: array of the form\n",
    "        \n",
    "                                    [[\"div\", {\"role\": \"option\"}], \n",
    "                                    [\"div\", {\"aria-label\": \"Reading Pane\"}], \n",
    "                                    ...]\n",
    "\n",
    "        which specifies the name (\"div\", \"span\") and attributes ({\"id\": [\"test1\", \"test2\"], \"aria-label\": \"pane\"})\n",
    "        from outer to inner tags, iteratively going down specificity levels\n",
    "\n",
    "        __ Description __\n",
    "        iterates through the supplied \"soup\" html looking for tags whose parrents match all the supplied \"html_tags\"\n",
    "\n",
    "        __ Return __\n",
    "        [htmltag1, htmltag2, htmltag3]: array of html tags that fit the search requirement\n",
    "        \"\"\"\n",
    "\n",
    "        structure_depth  = len(html_tags_array)\n",
    "        debug_counter = 0\n",
    "\n",
    "        try:\n",
    "            if(structure_depth != 1):\n",
    "                # 1 - unpack the first structure\n",
    "                current_structure = soup.find(\n",
    "                    html_tags_array[0][0], attrs=html_tags_array[0][1])\n",
    "\n",
    "                # 2 - unpack further structures until we get to the last one\n",
    "                for i in range(1, structure_depth - 1):\n",
    "                    debug_counter += 1\n",
    "                    name = html_tags_array[i][0]\n",
    "                    attrs = html_tags_array[i][1]\n",
    "                    current_structure = current_structure.find(names, attrs=attrs)\n",
    "                # 3 - extract all matches from the lowest structure\n",
    "                current_structure = current_structure.find_all(\n",
    "                    html_tags_array[-1][0], attrs=html_tags_array[-1][1])\n",
    "            else:\n",
    "                # 1 - in the special case that only one structure is specified\n",
    "                current_structure = soup.find_all(\n",
    "                    html_tags_array[0][0], attrs=html_tags_array[0][1])\n",
    "\n",
    "            return current_structure\n",
    "            \n",
    "        except AttributeError:\n",
    "            # Error when an entry is missing\n",
    "            print(\"The page does not have the html element:\\n\\t[%s, %s]\"\n",
    "                  % (html_tags_array[debug_counter], html_tags_array[debug_counter]))\n",
    "            \n",
    "            return \"\"\n",
    "        \n",
    "    def supp_extract_text(self, soup, html_tags_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [soup] soup: html to extract from formatted with BeautifulSoup\n",
    "        html_tags_array: array of the form\n",
    "        \n",
    "        [[\"div\", {\"role\": \"option\"}], \n",
    "        [\"div\", {\"aria-label\": \"Reading Pane\"}], \n",
    "        ...]\n",
    "\n",
    "        which specifies the name (\"div\", \"span\") and attributes ({\"id\": [\"test1\", \"test2\"], \"aria-label\": \"pane\"})\n",
    "        from outer to inner tags, iteratively going down specificity levels\n",
    "\n",
    "        __ Description __\n",
    "        iterates through the supplied \"soup\" html looking for tags whose parrents match all the supplied \"html_tags\"\n",
    "        then a text array is extracted from this tag\n",
    "\n",
    "        __ Return __\n",
    "        [array] matching text in the innter structure\n",
    "        \"\"\"\n",
    "\n",
    "        html_structure = self.supp_extract_html(soup, html_tags_array)\n",
    "        \n",
    "        # 1 - take all of the tags found and extract text\n",
    "        array_to_return = [i.get_text().strip() for i in html_structure]\n",
    "        \n",
    "        return array_to_return\n",
    "        \n",
    "    def supp_write_to_element(self, element_xpath, fill_value):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] element_xpath: element to look for e.g. //div[@id=|password|]\n",
    "        [str] fill_value: what to write in the form\n",
    "\n",
    "        __ Description __\n",
    "        enters the \"fill_value\" into the chosen \"element\"\n",
    "        \"\"\"\n",
    "        self.supp_wait_for_xpath(element_xpath, \"input_box\")\n",
    "        \n",
    "        element = self.driver.find_element_by_xpath(element_xpath)\n",
    "        if(element):\n",
    "            element.send_keys(fill_value)\n",
    "        else:\n",
    "            print(\"**> Element with xpath %s does not exist\" %element_xpath)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def supp_wait_for_xpath(self, xpath, description):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] xpath: xpath to wait for\n",
    "        [str] description: the object that is trying to be located. will be printed to console. \n",
    "                           \"NA\" to skip\n",
    "\n",
    "        __ Description __\n",
    "        pauses the browser until \"xpath\" is loaded on the page\n",
    "        \"\"\"\n",
    "\n",
    "        if(description != \"NA\"):\n",
    "            print(\"  > Waiting for \\\"%s\\\" to load\" %(description))\n",
    "            \n",
    "        self.WebDriverWaiter.until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, xpath)), \n",
    "            message=\"Did not find %s within the timeout time you set of %i\"%(xpath, self.timeout)\n",
    "        )\n",
    "        \n",
    "    def supp_click(self, xpath):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] xpath: xpath of object to click\n",
    "\n",
    "        __ Description __\n",
    "        clicks the element\n",
    "        \"\"\"\n",
    "        print(self.driver.find_element_by_xpath(xpath))\n",
    "        self.driver.find_element_by_xpath(xpath).click()\n",
    "        \n",
    "    def supp_load_soup(self):\n",
    "        \"\"\"\n",
    "        Loads up a soup of all the html on the visible page\n",
    "        __ Returns __\n",
    "        Soup Object to search\n",
    "        \"\"\"\n",
    "        html = self.driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        return soup\n",
    "    \n",
    "    def refresh(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        Resets variables of bot class and reload page\n",
    "        \"\"\"\n",
    "\n",
    "        self.driver.get(self.url)\n",
    "        self.supp_wait_for_xpath(self.succesful_login_xpath, \"main page\")\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        clears the pandas_out array to the initial value\n",
    "        \"\"\"\n",
    "\n",
    "        self.pandas_scraped = pd.DataFrame(columns=self.pandas_columns)\n",
    "\n",
    "    def save_data(self, file_name=\"pandas_out\", ext=\"csv\"):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] file_name: the file to save to. provide .pkl or .csv extension\n",
    "        \n",
    "        __ Description __\n",
    "        Saves data accumulated in \"pandas_out\" to output file\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1 - create output directory\n",
    "        if not os.path.exists(\"./output\"):\n",
    "            os.mkdir(\"output\")\n",
    "\n",
    "        # 2 - cut any extensions that were given by accident\n",
    "        file_name = file_name.split(\".\")[0]\n",
    "        file_name = \"./output/%s\" % (file_name)\n",
    "        \n",
    "        if(ext == \"pkl\"):\n",
    "            self.pandas_scraped.to_pickle(\"%s.pkl\" % file_name)\n",
    "        else:\n",
    "            self.pandas_scraped.to_csv(\"%s.csv\" % file_name)\n",
    "\n",
    "    def date_from_string(self, date_string):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] date_string: either day of week or \"18 May 2019\"\n",
    "\n",
    "        __ Description __\n",
    "        convert to an array numerical date values. if a weekday was supplied, find the nearest previous date\n",
    "\n",
    "        __ Return __\n",
    "        [year, month, day] date: array of the date\n",
    "        \"\"\"\n",
    "\n",
    "        weekday_list = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",\n",
    "                        \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "\n",
    "\n",
    "        if (date_string in weekday_list):\n",
    "            # 1 - set loop parameters\n",
    "            date = datetime.date.today()\n",
    "            date_shift = datetime.timedelta(days = 1)\n",
    "            date_found = False\n",
    "\n",
    "            # 2 - decrease date, until the weekday_list match\n",
    "            while(not date_found):\n",
    "                date = date - date_shift\n",
    "                day_of_the_week_long = weekday_list[date.weekday()]\n",
    "                day_of_the_week_short = weekday_list[date.weekday() + 7]\n",
    "                if((day_of_the_week_long == date_string) or (day_of_the_week_short == date_string)):\n",
    "                    date_found = True\n",
    "        else:\n",
    "            date = datetime.datetime.strptime(date_string, '%d %B %Y')\n",
    "\n",
    "        date_array = [date.year, date.month, date.day]\n",
    "        return date_array\n",
    "\n",
    "    def string_from_date(self, date_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [year, month, day] date: array of the date\n",
    "\n",
    "        __ Description __\n",
    "        converts the array to string representation \"18 May 2019\"\n",
    "\n",
    "        __ Return __\n",
    "        [str] date_string\n",
    "        \"\"\"\n",
    "\n",
    "        date = datetime.datetime(date_array[0], date_array[1], date_array[2])\n",
    "        return date.strftime(\"%d %B %Y\")    \n",
    "\n",
    "    def datetime_from_date(self, date_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [year, month, day] date: array of the date\n",
    "\n",
    "        __ Description __\n",
    "        converts the array to a datetime object\n",
    "\n",
    "        __ Return __\n",
    "        [datetime] datetimeObject\n",
    "        \"\"\"\n",
    "        return datetime.datetime(date_array[0], date_array[1], date_array[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Custom Wait Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class wait_for_content_forwarded():\n",
    "  \"\"\"Checking that IF there is a forwarded message, that it has been loaded\n",
    "\n",
    "  returns True if there is no forwarding message or it has been loaded\n",
    "\n",
    "  To be used in the following way:\n",
    "  formWebDriverWait.until(wait_for_content_forwarded())\n",
    "  \"\"\"\n",
    "\n",
    "  def __call__(self, driver):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    driver: the WebDriverWait.until(xxx) calls method xxx with 'driver' as the first \n",
    "    argument.\n",
    "\n",
    "    __ Description __\n",
    "    ensure that any forwarded email is fully loaded\n",
    "\n",
    "    a forwarded email has a non empty <div of forwarded email> in the following positon:\n",
    "\n",
    "    <div aria-label='Reading-Pane> ..... \n",
    "        <div>....</div>\n",
    "        <div>        <---------- div[2]\n",
    "            <div>...</div>\n",
    "            etc. etc.\n",
    "            <div of forwarded email> <----------- NON empty when there is forwarding\n",
    "            <div>...</div>        <---------- div[last()]\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    __ Return __\n",
    "    True: if forwarded email loaded\n",
    "    False: if forwaded email has NOT loaded\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1 - test if there is a forwarded section, by checking that the <div of forwarded email> is not empty\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@aria-label='Reading Pane']/div[2]/div[last()-1]/*\")\n",
    "    except NoSuchElementException:\n",
    "        #  if no email is being forwarded then we don't have to wait\n",
    "        return True\n",
    "\n",
    "    # 2 - IF there is a forwarded email, wait for the body of the forwarded email to load\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@id='Conversation.FossilizedTextBody']/div[1]\")\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        #  treurn flase if the email has not loaded yet\n",
    "        return False\n",
    "\n",
    "class wait_for_chat_update():\n",
    "  \"\"\"Checking that Skype chat has updated after scrolling has been performed\n",
    "\n",
    "  To be used in the following way:\n",
    "  formWebDriverWait.until(wait_for_chat_update(old_top_message))\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, top_message_text_old):\n",
    "      self.top_message_text_old = top_message_text_old\n",
    "      \n",
    "  def __call__(self, driver):\n",
    "    \"\"\"\n",
    "    __ Description __\n",
    "    compares the id of the top message after scrolling. \n",
    "    if scrolling has stopped (end of conversation of loading) the id will remain the same\n",
    "\n",
    "    __ Return __\n",
    "    True: if text stayed the same - need to perform a click action\n",
    "    False: if text has changed - can continue scrolling\n",
    "    \"\"\"\n",
    "\n",
    "    ########################################xpaths\n",
    "    chatBox_xpath = \"//div[@style='position: relative; display: flex; flex-direction: row; flex-grow: 1; flex-shrink: 1; overflow: hidden; align-items: stretch; background-color: rgb(255, 255, 255);']\"\n",
    "    ########################################\n",
    "    \n",
    "    chatBox = driver.find_element_by_xpath(chatBox_xpath).find_elements_by_xpath(\"//div[@role='region']\")\n",
    "\n",
    "    top_message_text_new = chatBox[0].id\n",
    "    \n",
    "    if(top_message_text_new == self.top_message_text_old):\n",
    "        # print(\"clicked and no change\")\n",
    "        return False\n",
    "    else:\n",
    "        # print(\"clicking has caused content to load\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Outlook Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class outlook_bot(selenium_bot):\n",
    "    \"\"\"bot to extract email content from outlook\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, browser, timeout, save_period=5, url=\"https://mail.sinobestech.com.hk/owa\", succesful_login_xpath = \"//div[@class = 'flex flexcolumn']\"):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] browser: \"Firefox\" or \"Chrome\"\n",
    "        [float] timeout: how long to wait for tiemouts on the page\n",
    "        [int] save_period: during scraping of email, how often to save an output file. default every 5 emails\n",
    "\n",
    "        __ Description __\n",
    "        initialisation of web driver and outlook variables\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - setup driver\n",
    "        selenium_bot.__init__(self, browser, timeout, int(save_period), url, succesful_login_xpath)\n",
    "\n",
    "        # 2 - setup outlook environment\n",
    "        self.__setup_outlook()\n",
    "        \n",
    "    def __setup_outlook(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        Sets up supporting objects for outlook\n",
    "\n",
    "        self.pandas_scraped: ouput dataframe with keys:\n",
    "        [ \"From\", \"Date\", \"Subject\", \"Content_Conversation\", \"Content_Forwarded\"]\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - pandas dataframe\n",
    "        self.pandas_columns = [ \"From\", \"Date\", \"Subject\", \"Content_Conversation\", \"Content_Forwarded\"]\n",
    "        self.pandas_scraped = pd.DataFrame(columns=self.pandas_columns)\n",
    "\n",
    "        self.scrape_filters_set = False\n",
    "        \n",
    "        # 2 - debugging\n",
    "        self.entry_missing_array = [0] * 5\n",
    "        self.email_current = -1\n",
    "        self.email_total = -1\n",
    "\n",
    "    def outlook_login(self, outlook_id, password):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] outlook_id: email to log on with\n",
    "        [str] password:   password\n",
    "\n",
    "        __ Description __\n",
    "        logs into outlook\n",
    "        \"\"\"\n",
    "        print(\"==> outlook_login start\")\n",
    "        \n",
    "        # 1 - access the outlook page\n",
    "        self.supp_wait_for_xpath(\"//input[@id='username']\", \"user_name_input_field\")\n",
    "\n",
    "        # 2 - locate credential fields and fill them in\n",
    "        self.supp_write_to_element(\"//input[@id='username']\", outlook_id)\n",
    "        self.supp_write_to_element(\"//input[@id='password']\", password)\n",
    "        print(type(self.driver.find_element_by_xpath(\n",
    "            \"//div[@onclick='clkLgn()']\")))\n",
    "        self.driver.find_element_by_xpath(\n",
    "            \"//div[@onclick='clkLgn()']\").click()\n",
    "\n",
    "        # 3 - ensure that login is succesfull and wait for emails to load\n",
    "        self.supp_wait_for_xpath(self.succesful_login_xpath, \"main_page\")\n",
    "\n",
    "        print(\"==> outlook_login end\\n\")\n",
    "\n",
    "    def outlook_scrape_setup(self, date_min, date_max, only_unread=False, scan_min=0, scan_max=9999):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [year, month, day] date_min/date_max:   date range to scrape\n",
    "        [bool] only_unread:                     whether only unread emails should be scraped\n",
    "        [int] scan_min/max:                     email range to scrape\n",
    "\n",
    "        __ Description __\n",
    "        sets values in preparation for scraping outlook\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"==> outlook_scrape_setup start\")\n",
    "\n",
    "        self.criteria = {}\n",
    "\n",
    "        # 1 - set dates if supplied\n",
    "        if(date_min):\n",
    "            self.criteria['date_min'] = date_min\n",
    "            print(\"  > Minimum date:\\t\",\n",
    "                  datetime.datetime(date_min[0], date_min[1], date_min[2]).strftime(\"%A, %d %b %Y\"))\n",
    "        else:\n",
    "            self.criteria['date_min'] = [1, 1, 1]\n",
    "            print(\"  > No minimum date\")\n",
    "\n",
    "        if(date_max):\n",
    "            self.criteria['date_max'] = date_max\n",
    "            print(\"  > Maximal date:\\t\",\n",
    "                  datetime.datetime(date_max[0], date_max[1], date_max[2]).strftime(\"%A, %d %b %Y\"))\n",
    "        else:\n",
    "            self.criteria['date_max'] = [8888, 1, 1]  # highest possible date\n",
    "            print(\"  > No maximal date\")\n",
    "\n",
    "        # 2 - read/unread\n",
    "        self.criteria['only_unread'] = only_unread\n",
    "        if(only_unread):\n",
    "            print(\"  > Scraping only unread emails\")\n",
    "\n",
    "        # 3 -  min\n",
    "        self.criteria['scan_min'] = scan_min\n",
    "        self.criteria['scan_max'] = scan_max\n",
    "        print(f\"  > Email index start:\\t{scan_min}\\n  > Email index end:\\t{scan_max}\")\n",
    "\n",
    "        self.scrape_filters_set = True\n",
    "\n",
    "        print(\"==> outlook_scrape_setup end\\n\")\n",
    "\n",
    "        \n",
    "    def outlook_scrape(self, file_name=\"pandas_out\", ext=\"csv\"):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] filename:         to which to save dataframe\n",
    "        [str] ext:              format to save as - pkl or csv\n",
    "\n",
    "        __ Description __\n",
    "        Iterates through the emails and parses out information into pandas dataframe\n",
    "        \"\"\"\n",
    "        ########################################xpaths\n",
    "        inbox_mail_L1_xp = \"//div[@class = 'flex flexcolumn']\"\n",
    "        inbox_mail_L2_xp = \"//div[@role ='option']\"\n",
    "        inbox_mail_soup = [[\"div\", {\"class\": \"flex flexcolumn\"}],\n",
    "                           [\"div\", {\"role\": \"option\"}]]\n",
    "        ########################################\n",
    "        \n",
    "        print(\"==> outlook_scrape start\")\n",
    "            \n",
    "        # 0 - prepare variable\n",
    "        self.refresh()\n",
    "        self.supp_wait_for_xpath(self.succesful_login_xpath, \"NA\")\n",
    "\n",
    "        if(not self.scrape_filters_set):\n",
    "            self.outlook_scrape_setup(None, None)\n",
    "        inbox_cycle = True\n",
    "        email_loop_no = 0\n",
    "        email_base_index = 0            # base index is required to stitch email numbers across different loops\n",
    "        uniqueID_already_scraped = set()\n",
    "\n",
    "        while(inbox_cycle):\n",
    "\n",
    "            # 1 - [XPATH] extract unique tag and webelement of each email\n",
    "            visible_webElements = self.driver.find_element_by_xpath(inbox_mail_L1_xp).find_elements_by_xpath(inbox_mail_L2_xp)\n",
    "            visible_uniqueID = [i.text for i in visible_webElements]\n",
    "\n",
    "            # 2 - [SOUP] extract metadata of visible mail\n",
    "            soup = self.supp_load_soup()\n",
    "            visible_metadataRaw = self.supp_extract_html(soup, inbox_mail_soup)\n",
    "            visible_metadata = []\n",
    "            for i in visible_metadataRaw:\n",
    "                visible_metadata.append({\"date\": self.outlook_inbox_date(i),\n",
    "                                         \"unread\": self.outlook_inbox_unread(i)})\n",
    "\n",
    "            # 3 - only iterate through unscraped mail i.e. uniqueID is not in \"uniqueID_already_scraped\" set\n",
    "            emails_to_scrape = []\n",
    "            i = 0\n",
    "            for email_webElement, email_uniqueID, email_metadata in zip(visible_webElements, visible_uniqueID, visible_metadata):\n",
    "                if(email_uniqueID not in uniqueID_already_scraped):\n",
    "                    \n",
    "                    # 3a - add the email number\n",
    "                    email_metadata[\"email_no\"] = email_base_index + i\n",
    "                    i += 1\n",
    "                    # 3b - store email id and email_metadata for further extraction\n",
    "                    emails_to_scrape.append({\"email_webElement\": email_webElement,\n",
    "                                            \"email_metadata\": email_metadata})\n",
    "                    # 3c - store the unqiue tag to prevent scraping it in the future\n",
    "                    uniqueID_already_scraped.add(email_uniqueID)\n",
    "\n",
    "\n",
    "            print(\"  [Loop No.%i]:\\t%i unique emails found in inbox so far\" % (email_loop_no, len(uniqueID_already_scraped)))\n",
    "\n",
    "            # 4 - iterate through only the new emails\n",
    "            for i, email in enumerate(emails_to_scrape):\n",
    "                \n",
    "                # a - check that email_metadata fulfills criteria\n",
    "                criteria_satisfied = self.criteria_check(email['email_metadata'],\n",
    "                                                         self.criteria)\n",
    "\n",
    "                if(criteria_satisfied):\n",
    "                    print(self.outlook_scrape_print_progress(email['email_metadata']))\n",
    "                    email_content = self.outlook_scrape_email(email['email_webElement'])\n",
    "                    self.pandas_scraped = self.pandas_scraped.append(email_content, ignore_index=True)\n",
    "                    \n",
    "                    # b - write to file periodically during intense data writting\n",
    "                    if(((email['email_metadata']['email_no'\n",
    "                    ] - self.criteria['scan_min'] + 1) % self.save_period) == 0):\n",
    "                        self.save_data(file_name, ext)\n",
    "                    \n",
    "            # 5 - click on last mail (to scroll down)\n",
    "            self.outlook_scrape_email(emails_to_scrape[-1]['email_webElement'])\n",
    "            \n",
    "            # a - set variables for next loop\n",
    "            email_loop_no += 1\n",
    "            email_base_index = len(uniqueID_already_scraped)\n",
    "\n",
    "            # b - check against max emails scraped\n",
    "            if(email_base_index > self.criteria['scan_max']):\n",
    "                # if we have scraped all the emails, stop\n",
    "                inbox_cycle = False\n",
    "\n",
    "            # c - check against no scrolling (same emails displayed)\n",
    "            visible_idx_new = self.driver.find_element_by_xpath(inbox_mail_L1_xp).find_elements_by_xpath(inbox_mail_L2_xp)\n",
    "            if (visible_webElements == visible_idx_new):\n",
    "                inbox_cycle = False\n",
    "\n",
    "        # 5 - save data and exit\n",
    "        print(\"==> Scraped %i emails that fit the criteria\" %(len(uniqueID_already_scraped)))        \n",
    "        self.save_data(file_name, ext)        \n",
    "        print(\"==> outlook_scrape end\")\n",
    "\n",
    "    def outlook_scrape_print_progress(self, email_metadata):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [dict] email_metadata:          {\"date\":        [year, month, day] of email,\n",
    "                                         \"unread\":      [bool] read status of email,\n",
    "                                         \"email_no\":    [int] top email is 0}\n",
    "\n",
    "        __ Description __\n",
    "        generates string to print to console about the emial currently being extracted\n",
    "\n",
    "        __ Returns __\n",
    "        [str] string to print to console describing email being extracted\n",
    "        \"\"\"\n",
    "        email_no = email_metadata['email_no']\n",
    "        date = email_metadata['date']\n",
    "        unread = email_metadata['unread']\n",
    "\n",
    "        # 1 - read undread\n",
    "        string_read = \"\\t[Read]\"\n",
    "        if(unread):\n",
    "            string_read = \"\\t[Unread]\"\n",
    "            \n",
    "        # 2 - date\n",
    "        string_date = \"\\t[\" + datetime.datetime(date[0], date[1], date[2]).strftime(\"%A, %d %b %Y\") + \"]\"\n",
    "\n",
    "        string_to_print = f\"  > Scraping Email {email_no}\" + string_read + string_date\n",
    "\n",
    "        return string_to_print\n",
    "        \n",
    "    def outlook_scrape_email(self, email_webElement):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [web_element] email_webElement:            element found with xPath  \"self.driver.find_element_by_xpath(...)\"\n",
    "\n",
    "        __ Description __\n",
    "        extacts data from the given email (passed as a web_element)\n",
    "        \n",
    "        __ Return __\n",
    "        [dict]          {\"From\": e_from,\n",
    "                        \"Date\": e_date,\n",
    "                        \"Subject\": e_subject,\n",
    "                        \"Content_Conversation\": e_content_conversation,\n",
    "                        \"Content_Forwarded\": e_content_forwarded}\n",
    "        \"\"\"\n",
    "        # 1 - load up the email_webElement and wait for for load\n",
    "        try:\n",
    "            email_webElement.click()\n",
    "            self.supp_wait_for_xpath(\"//div[@id = 'Item.MessageUniqueBody']\", \"NA\")\n",
    "            self.WebDriverWaiter.until(wait_for_content_forwarded())\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\n",
    "                \"**> Email failed to load. Increase timeout (currently %.1fs)\" % (self.timeout))\n",
    "            return\n",
    "\n",
    "        # 2 - extract html on the page. soup is the chad way to search this html\n",
    "        soup = self.supp_load_soup()\n",
    "\n",
    "        # a - subject\n",
    "        self.entry_current = 0\n",
    "        e_subject = \"\".join(self.supp_extract_text(soup,\n",
    "                                     [[\"div\", {\"aria-label\": \"Reading Pane\"} ],\n",
    "                                      [\"div\", {'role': \"heading\", \"aria-level\": \"2\"}]]))\n",
    "        \n",
    "        # b - from\n",
    "        self.entry_current = 1\n",
    "        e_from = \"\".join(self.supp_extract_text(soup,\n",
    "                                        [[\"div\", {\"aria-label\": \"Persona card\"} ]]))\n",
    "        match_groups = re.search(\"([^<]*)(.*)?\", e_from) # remove email_webElement <ilya.antonv....>\n",
    "        e_from = match_groups.group(1).strip()\n",
    "\n",
    "        # c - date and time\n",
    "        self.entry_current = 2\n",
    "        e_date = \"\".join(self.supp_extract_text(soup,\n",
    "                                         [[\"div\", {\"class\": \"_rp_f8\"}],\n",
    "                                          [\"span\", {\"class\": \"allowTextSelection\"} ]]))\n",
    "\n",
    "        # d - email_webElement content\n",
    "        self.entry_current = 3\n",
    "        e_content_conversation = \"\".join(self.supp_extract_text(soup,\n",
    "                                            [[\"div\", {\"aria-label\": \"Reading Pane\"}],\n",
    "                                             [\"div\", {\"role\": \"document\"}]]))\n",
    "\n",
    "        self.entry_current = 4\n",
    "        e_content_forwarded = \"\".join(self.supp_extract_text(soup,\n",
    "                                         [[\"div\", {\"aria-label\": \"Reading Pane\"}],\n",
    "                                          [\"div\", {\"id\": \"Conversation.FossilizedTextBody\"}]]))\n",
    "\n",
    "        #print(\"_______Subject________\\n%s\\n\" %e_subject)\n",
    "        #print(\"_______From________\\n%s\\n\" %e_from)        \n",
    "        #print(\"_______Date________\\n%s\\n\" %e_date)        \n",
    "        #print(\"_______Content_Conversation________\\n%s\\n\" %e_content_conversation)        \n",
    "        #print(\"_______Content_Forwarded________\\n%s\\n\" %e_content_forwarded)\n",
    "        \n",
    "        # 6 - structure building and return\n",
    "        email_entry = {\"From\": e_from,\n",
    "                       \"Date\": e_date,\n",
    "                       \"Subject\": e_subject,\n",
    "                       \"Content_Conversation\": e_content_conversation,\n",
    "                       \"Content_Forwarded\": e_content_forwarded}\n",
    "        \n",
    "        return email_entry\n",
    "    \n",
    "    def outlook_inbox_date(self, inbox_tag):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [soup] inbox_tag: a html tag of an particular email in the inbox\n",
    "\n",
    "        __ Description __\n",
    "        extracts a date of the email in the inbox column by searching the \"inbox_tag\"\n",
    "\n",
    "        __ Returns __\n",
    "        [day, month, year]\n",
    "        \"\"\"\n",
    "\n",
    "        ########################################\n",
    "        date_attr = {\"class\": [\"_lvv_M\"]}\n",
    "        ########################################\n",
    "\n",
    "        # 1 - extract date tag\n",
    "        date_tag = inbox_tag.find(attrs=date_attr)\n",
    "        date_inbox = date_tag.get_text()\n",
    "\n",
    "        # 2 - split date put by slashes. this will work for old entries\n",
    "        date_return = date_inbox.split(\"/\")\n",
    "        date_return = date_return[::-1] # reverse order so that [year, month, day]\n",
    "        \n",
    "        if(len(date_return) != 3):\n",
    "            # 3 - for email sent this week, the first string is the day of the week, which is converted to [year, month, day]\n",
    "            weekday = date_inbox.split(\" \")[0]\n",
    "            date_return = self.date_from_string(weekday)\n",
    "\n",
    "        # 3 - convert to int\n",
    "        date_return = [int(i) for i in date_return]\n",
    "            \n",
    "        return date_return\n",
    "\n",
    "    def outlook_inbox_unread(self, inbox_tag):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [soup] inbox_tag: a html tag of an particular email in the inbox\n",
    "\n",
    "        __ Description __\n",
    "        checks if email unread or not\n",
    "\n",
    "        __ Returns __\n",
    "        True if unread. False otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - read email have a \"_lvv_y_\" tag\n",
    "        mg = re.search(\"\\s_lvv_y\\s\", str(inbox_tag))\n",
    "\n",
    "        # 2 - check if match was found, indicating that email has been read\n",
    "        if(mg):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def criteria_check(self, email_metadata, criteria):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [dict] email_metadata:  {'email_no':   \t[int]  email number as it appears in inbox\n",
    "                                 'date':       \t[year, month, day] of email\n",
    "                                 'unread':     \t[bool]  read status of email}\n",
    "\n",
    "        [dict] criteria:        {'scan_min':   [int] range to scrape (0 for top email)\n",
    "                                 'scan_max':\n",
    "                                 'date_min':    [int] date range to scrape\n",
    "                                 'data_max':\n",
    "                                 'only_unread': [bool] whether to scrape only unread emails}\n",
    "\n",
    "        __ Description __\n",
    "        checks whether email should be scraped based off it's email_metadata\n",
    "\n",
    "        __ Return __\n",
    "        True/False\n",
    "        \"\"\"\n",
    "        # 1 - extract criteria info\n",
    "        date_min = criteria['date_min']\n",
    "        date_max = criteria['date_max']\n",
    "        date_min = datetime.datetime(date_min[0], date_min[1], date_min[2])\n",
    "        date_max = datetime.datetime(date_max[0], date_max[1], date_max[2])\n",
    "\n",
    "        # 2 - extract email_metadata\n",
    "        unread = email_metadata['unread']\n",
    "        email_no = email_metadata['email_no']\n",
    "        date = email_metadata['date']\n",
    "        date = datetime.datetime(date[0],date[1],date[2])    \n",
    "\n",
    "        return_val = False\n",
    "\n",
    "        ########################################\n",
    "        # ⦿ Perform check\n",
    "        ########################################\n",
    "        # 1 - check that email is within indicies\n",
    "        if((criteria['scan_min'] <= email_no) and (email_no <= criteria['scan_max'])):\n",
    "            \n",
    "            # 2 - check date\n",
    "            if ((date_min <= date) and (date <= date_max)):\n",
    "                \n",
    "                # 3 - if scraping only unread, check unread status\n",
    "                if(criteria['only_unread']):\n",
    "                    if(unread):\n",
    "                        return_val = True\n",
    "                    else:\n",
    "                        return_val = False\n",
    "                else:\n",
    "                    return_val = True\n",
    "\n",
    "        return return_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Outlook Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> setup_browser start\n",
      "  > Starting new Chrome server\n",
      "==> setup_browser end\n",
      "\n",
      "==> outlook_login start\n",
      "  > Waiting for \"user_name_input_field\" to load\n",
      "  > Waiting for \"input_box\" to load\n",
      "  > Waiting for \"input_box\" to load\n",
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "  > Waiting for \"main_page\" to load\n",
      "==> outlook_login end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########################################\n",
    "outlook_id=\"programmer01@sbtgc.local\"\n",
    "password=\"3Zwl26EiY\"\n",
    "timeout=50                      # seconds to wait for page elements to load before quitting\n",
    "browser=\"chrome\"                # firefox of chrome\n",
    "########################################\n",
    "########################################\n",
    "outlook_class = outlook_bot(browser, timeout)\n",
    "outlook_class.outlook_login(outlook_id, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> outlook_scrape_setup start\n",
      "  > No minimum date\n",
      "  > Maximal date:\t Saturday, 25 May 2019\n",
      "  > Email index start:\t0\n",
      "  > Email index end:\t1000\n",
      "==> outlook_scrape_setup end\n",
      "\n",
      "==> outlook_scrape start\n",
      "  > Waiting for \"main page\" to load\n",
      "  [Loop No.0]:\t25 unique emails found in inbox so far\n",
      "  > Scraping Email 0\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 1\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 2\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 3\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 4\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 5\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 6\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 7\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 8\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 9\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 10\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 11\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 12\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 13\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 14\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 15\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 16\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 17\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 18\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 19\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 20\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 21\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 22\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 23\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 24\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  [Loop No.1]:\t27 unique emails found in inbox so far\n",
      "  > Scraping Email 25\t[Read]\t[Friday, 12 Apr 2019]\n",
      "  > Scraping Email 26\t[Read]\t[Friday, 12 Apr 2019]\n",
      "==> Scraped 27 emails that fit the criteria\n",
      "==> outlook_scrape end\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########################################\n",
    "unread_only = False\n",
    "date_min = None                 # either None or [2018, 1, 1]\n",
    "date_max = [2019, 5, 25]        # either None or [2018, 1, 1]\n",
    "# optional arguments (can call scrape_filters without them)\n",
    "# top email has an id=0, second email id=1 etc.\n",
    "id_min = 0                      # set 0 to include all emails\n",
    "id_max = 1000                   # set to 1000 to include all emails\n",
    "########################################\n",
    "########################################\n",
    "outlook_class.outlook_scrape_setup(date_min, date_max, unread_only, id_min, id_max)\n",
    "outlook_class.outlook_scrape(\"outlook\",\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Content_Conversation</th>\n",
       "      <th>Content_Forwarded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Yesterday, 18:13</td>\n",
       "      <td>For Bussiness</td>\n",
       "      <td></td>\n",
       "      <td>From: Litchi &lt;litchi.lv@agradeflash.com&gt; \\nSen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan Tsang</td>\n",
       "      <td>Tue 14/05, 00:39</td>\n",
       "      <td>[深圳市晟源電子有限公司] offers - 12/04/2019</td>\n",
       "      <td>[深圳市晟源電子有限公司]\\n\\n\\n\\n\\nPart number : product T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Tsang</td>\n",
       "      <td>Mon 13/05, 23:34</td>\n",
       "      <td>testesttest</td>\n",
       "      <td>W25Q64FWZPIGS 10000  \\n\\n\\n\\nUncertainties in ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antonov, Ilya (2013)</td>\n",
       "      <td>Sun 12/05, 15:44</td>\n",
       "      <td>BanzGames - заказ 1606. Статус заказа изменен ...</td>\n",
       "      <td>An email message to forward\\n\\n\\nBegin forward...</td>\n",
       "      <td>From: BanzGames &lt;info@banzgames.ru&gt;\\n\\nSubject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Wed 08/05, 09:04</td>\n",
       "      <td>Good Power offer, pls hlp to update, tkx!</td>\n",
       "      <td></td>\n",
       "      <td>From: Lisa Lao &lt;lisa@nxelectronics.com&gt; \\nSent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Mon 06/05, 14:29</td>\n",
       "      <td>offer for bid - AB Sunshine</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Mon 06/05, 14:22</td>\n",
       "      <td>Offer OM (   Spectek offer for 6.5.19 )</td>\n",
       "      <td></td>\n",
       "      <td>From: Irene Wan &lt;irenewan@sinobestech.com.hk&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 26/04, 16:43</td>\n",
       "      <td>Please quote</td>\n",
       "      <td></td>\n",
       "      <td>-----Original Message-----\\n\\nFrom: 白菜 &lt;251933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 26/04, 16:17</td>\n",
       "      <td>AMTI offer, pls hlp to update, tkx!</td>\n",
       "      <td></td>\n",
       "      <td>From: Lisa Lao &lt;lisa@nxelectronics.com&gt; \\nSent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Thu 25/04, 12:44</td>\n",
       "      <td>[offer] E-energy (25 Apr)</td>\n",
       "      <td></td>\n",
       "      <td>From: Amy Guo &lt;amyguo@nxelectronics.com&gt; \\nSen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Thu 25/04, 12:12</td>\n",
       "      <td>Avnet Micron stock list</td>\n",
       "      <td></td>\n",
       "      <td>From: Daniel Yu &lt;daniel@sinobestech.com.hk&gt; \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Thu 25/04, 12:11</td>\n",
       "      <td>Offer OM (  Dram offer  )</td>\n",
       "      <td></td>\n",
       "      <td>From: Irene Wan &lt;irenewan@sinobestech.com.hk&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Mon 22/04, 21:10</td>\n",
       "      <td>offer- : R&amp;A offer-20190422</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Thu 18/04, 11:49</td>\n",
       "      <td>PLPC offer, pls help to input. Tks!</td>\n",
       "      <td></td>\n",
       "      <td>From: Winnie Wong &lt;winniewong@nxelectronics.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Irene Wan</td>\n",
       "      <td>Wed 17/04, 16:33</td>\n",
       "      <td>Offer dram/nand</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Wed 17/04, 14:18</td>\n",
       "      <td>[offer] Unotel Kr (17 Apr)</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Wed 17/04, 14:12</td>\n",
       "      <td>OM offer</td>\n",
       "      <td></td>\n",
       "      <td>From:\\nDoris Chang &lt;dorischang@sbit.com.tw&gt; \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Wed 17/04, 11:51</td>\n",
       "      <td>[require]  - [VIP Computers LLC (USA)] Require...</td>\n",
       "      <td></td>\n",
       "      <td>From: Rhoda To &lt;Rhoda@nxelectronics.com&gt; \\nSen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Wed 17/04, 11:45</td>\n",
       "      <td>Platinum offer, pls hlp to update, tkx!</td>\n",
       "      <td></td>\n",
       "      <td>From: Rhoda To &lt;Rhoda@nxelectronics.com&gt; \\nSen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Wed 17/04, 10:13</td>\n",
       "      <td>Offer IT ACTIONS</td>\n",
       "      <td></td>\n",
       "      <td>-----Original Message-----\\n\\nFrom: Irene Wan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Tue 16/04, 16:27</td>\n",
       "      <td>update 15/04/19 server stock</td>\n",
       "      <td>offer</td>\n",
       "      <td>From: Yuliya Grebenyuk &lt;juliagr@neo-mid.com.ua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Tue 16/04, 16:08</td>\n",
       "      <td>[offer]  - [R&amp;A ELECTRONICS CO., LTD / 伯仲電子有限公...</td>\n",
       "      <td>0ffer</td>\n",
       "      <td>From: Irene Chow &lt;irene@nxelectronics.com&gt; \\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Tue 16/04, 16:05</td>\n",
       "      <td>OEM  DDETC  file stock  for sale    fr EEtech ...</td>\n",
       "      <td>Offer</td>\n",
       "      <td>From: eetech &lt;eetech@ms67.hinet.net&gt; \\nSent: M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Tue 16/04, 15:51</td>\n",
       "      <td>Week 16 Order Inquiry</td>\n",
       "      <td></td>\n",
       "      <td>From: Su Jason &lt;jasonsuhk@gmail.com&gt; \\nSent: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Tue 16/04, 12:10</td>\n",
       "      <td>[offer]  - [OEM XS Inc] OEM XS SSD offers (16 ...</td>\n",
       "      <td>Offer</td>\n",
       "      <td>From: Albert Lo &lt;albertlo@sinobestech.com.hk&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bryan YAU</td>\n",
       "      <td>Sat 13/04, 16:13</td>\n",
       "      <td>blah</td>\n",
       "      <td>blah blah</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bryan YAU</td>\n",
       "      <td>Sat 13/04, 16:12</td>\n",
       "      <td>Title</td>\n",
       "      <td>blah blah blah</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:13</td>\n",
       "      <td>Amazing price/ Distributor: Server Samsung RAM</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:11</td>\n",
       "      <td>s2 offer</td>\n",
       "      <td>offer</td>\n",
       "      <td>From: Yoyo Chong \\nSent: Tuesday, April 9, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:11</td>\n",
       "      <td>in rely to your inquiry</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:09</td>\n",
       "      <td>[offer]  - [1st Technologies LTD] Offer 1st (P...</td>\n",
       "      <td>Offer – too general, not specific</td>\n",
       "      <td>From: Irene Wan \\nSent: Tuesday, April 9, 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:09</td>\n",
       "      <td>Offer OM (  Spectek offer for 9.4.19 )</td>\n",
       "      <td></td>\n",
       "      <td>From: Irene Wan \\nSent: Tuesday, April 9, 2019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:07</td>\n",
       "      <td>B&amp;S offer</td>\n",
       "      <td></td>\n",
       "      <td>From:\\nDoris Chang &lt;dorischang@sbit.com.tw&gt; \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 23:06</td>\n",
       "      <td>[offer]  - [Kaan Technologies Ltd]  (09 Apr 2019)</td>\n",
       "      <td></td>\n",
       "      <td>From: albertliu@sbit.com.tw &lt;albertliu@sbit.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:52</td>\n",
       "      <td>Apple Stocks Wholesale: iPhones and iPads for ...</td>\n",
       "      <td>We received offer, but sometimes we have no ex...</td>\n",
       "      <td>From: Leo Jolliffe &lt;leo@digitalcomgroup.net&gt; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:49</td>\n",
       "      <td>Offer OM (  Micron SSD )</td>\n",
       "      <td>Offer with quantity but no  price, you need to...</td>\n",
       "      <td>From: Irene Wan \\nSent: Wednesday, April 10, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:46</td>\n",
       "      <td>TAKE IT ALL BIDDING OFFER - Pan Electronic</td>\n",
       "      <td>offer</td>\n",
       "      <td>From:\\nDaniel Yu \\nSent: Thursday, April 11, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:39</td>\n",
       "      <td>Azure account</td>\n",
       "      <td>Please cehck with Kenneth, apparently Azure do...</td>\n",
       "      <td>From: Kenneth Chung &lt;kennethchung@sbit.com.tw&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:28</td>\n",
       "      <td>Offer -Toshiba Cards</td>\n",
       "      <td></td>\n",
       "      <td>From: Florence Lee \\nSent: Tuesday, April 9, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:26</td>\n",
       "      <td>an offer by our vendor - quantity we can guess...</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:25</td>\n",
       "      <td>inquiry - with description, part number and pr...</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:24</td>\n",
       "      <td>inquiry - quantity brand and part number</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:23</td>\n",
       "      <td>inquiry - two items on the same row</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:22</td>\n",
       "      <td>Web Inquiry</td>\n",
       "      <td>Our web site capture inquiry and notify ourselves</td>\n",
       "      <td>From: WebInquiry \\nSent: Tuesday, April 9, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:18</td>\n",
       "      <td>requirement</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:12</td>\n",
       "      <td>some format we used, may have Chinese Characte...</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:07</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:06</td>\n",
       "      <td>[VIP Computer Centre Limited] require (11 Apr ...</td>\n",
       "      <td>Only the number of pieces required are stated</td>\n",
       "      <td>From: Rhoda To \\nSent: Thursday, April 11, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:04</td>\n",
       "      <td>typical offer would be like this</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 22:02</td>\n",
       "      <td>Offer from US</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 21:55</td>\n",
       "      <td>[require]  - [TERABAY Co ., Ltd] requirement (...</td>\n",
       "      <td></td>\n",
       "      <td>From: Lisa Lao \\nSent: Friday, April 12, 2019 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 21:54</td>\n",
       "      <td>[offer]</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 21:52</td>\n",
       "      <td>A STANDARD FORAMT WILL BE LIKE</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 21:50</td>\n",
       "      <td>MISSING PRICE - OPEN FOR BID</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 18:20</td>\n",
       "      <td>model price - today's transaction</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 18:18</td>\n",
       "      <td>- [深圳市晟源電子有限公司] offers - 12/04/2019</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Henry Yau</td>\n",
       "      <td>Fri 12/04, 18:11</td>\n",
       "      <td>test from Henry</td>\n",
       "      <td>&lt;!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    From              Date  \\\n",
       "0              Henry Yau  Yesterday, 18:13   \n",
       "1             Alan Tsang  Tue 14/05, 00:39   \n",
       "2             Alan Tsang  Mon 13/05, 23:34   \n",
       "3   Antonov, Ilya (2013)  Sun 12/05, 15:44   \n",
       "4              Henry Yau  Wed 08/05, 09:04   \n",
       "5              Henry Yau  Mon 06/05, 14:29   \n",
       "6              Henry Yau  Mon 06/05, 14:22   \n",
       "7              Henry Yau  Fri 26/04, 16:43   \n",
       "8              Henry Yau  Fri 26/04, 16:17   \n",
       "9              Henry Yau  Thu 25/04, 12:44   \n",
       "10             Henry Yau  Thu 25/04, 12:12   \n",
       "11             Henry Yau  Thu 25/04, 12:11   \n",
       "12             Henry Yau  Mon 22/04, 21:10   \n",
       "13             Henry Yau  Thu 18/04, 11:49   \n",
       "14             Irene Wan  Wed 17/04, 16:33   \n",
       "15             Henry Yau  Wed 17/04, 14:18   \n",
       "16             Henry Yau  Wed 17/04, 14:12   \n",
       "17             Henry Yau  Wed 17/04, 11:51   \n",
       "18             Henry Yau  Wed 17/04, 11:45   \n",
       "19             Henry Yau  Wed 17/04, 10:13   \n",
       "20             Henry Yau  Tue 16/04, 16:27   \n",
       "21             Henry Yau  Tue 16/04, 16:08   \n",
       "22             Henry Yau  Tue 16/04, 16:05   \n",
       "23             Henry Yau  Tue 16/04, 15:51   \n",
       "24             Henry Yau  Tue 16/04, 12:10   \n",
       "25             bryan YAU  Sat 13/04, 16:13   \n",
       "26             bryan YAU  Sat 13/04, 16:12   \n",
       "27             Henry Yau  Fri 12/04, 23:13   \n",
       "28             Henry Yau  Fri 12/04, 23:11   \n",
       "29             Henry Yau  Fri 12/04, 23:11   \n",
       "30             Henry Yau  Fri 12/04, 23:09   \n",
       "31             Henry Yau  Fri 12/04, 23:09   \n",
       "32             Henry Yau  Fri 12/04, 23:07   \n",
       "33             Henry Yau  Fri 12/04, 23:06   \n",
       "34             Henry Yau  Fri 12/04, 22:52   \n",
       "35             Henry Yau  Fri 12/04, 22:49   \n",
       "36             Henry Yau  Fri 12/04, 22:46   \n",
       "37             Henry Yau  Fri 12/04, 22:39   \n",
       "38             Henry Yau  Fri 12/04, 22:28   \n",
       "39             Henry Yau  Fri 12/04, 22:26   \n",
       "40             Henry Yau  Fri 12/04, 22:25   \n",
       "41             Henry Yau  Fri 12/04, 22:24   \n",
       "42             Henry Yau  Fri 12/04, 22:23   \n",
       "43             Henry Yau  Fri 12/04, 22:22   \n",
       "44             Henry Yau  Fri 12/04, 22:18   \n",
       "45             Henry Yau  Fri 12/04, 22:12   \n",
       "46             Henry Yau  Fri 12/04, 22:07   \n",
       "47             Henry Yau  Fri 12/04, 22:06   \n",
       "48             Henry Yau  Fri 12/04, 22:04   \n",
       "49             Henry Yau  Fri 12/04, 22:02   \n",
       "50             Henry Yau  Fri 12/04, 21:55   \n",
       "51             Henry Yau  Fri 12/04, 21:54   \n",
       "52             Henry Yau  Fri 12/04, 21:52   \n",
       "53             Henry Yau  Fri 12/04, 21:50   \n",
       "54             Henry Yau  Fri 12/04, 18:20   \n",
       "55             Henry Yau  Fri 12/04, 18:18   \n",
       "56             Henry Yau  Fri 12/04, 18:11   \n",
       "\n",
       "                                              Subject  \\\n",
       "0                                       For Bussiness   \n",
       "1                   [深圳市晟源電子有限公司] offers - 12/04/2019   \n",
       "2                                         testesttest   \n",
       "3   BanzGames - заказ 1606. Статус заказа изменен ...   \n",
       "4           Good Power offer, pls hlp to update, tkx!   \n",
       "5                         offer for bid - AB Sunshine   \n",
       "6             Offer OM (   Spectek offer for 6.5.19 )   \n",
       "7                                        Please quote   \n",
       "8                 AMTI offer, pls hlp to update, tkx!   \n",
       "9                           [offer] E-energy (25 Apr)   \n",
       "10                            Avnet Micron stock list   \n",
       "11                          Offer OM (  Dram offer  )   \n",
       "12                        offer- : R&A offer-20190422   \n",
       "13                PLPC offer, pls help to input. Tks!   \n",
       "14                                    Offer dram/nand   \n",
       "15                         [offer] Unotel Kr (17 Apr)   \n",
       "16                                           OM offer   \n",
       "17  [require]  - [VIP Computers LLC (USA)] Require...   \n",
       "18            Platinum offer, pls hlp to update, tkx!   \n",
       "19                                   Offer IT ACTIONS   \n",
       "20                       update 15/04/19 server stock   \n",
       "21  [offer]  - [R&A ELECTRONICS CO., LTD / 伯仲電子有限公...   \n",
       "22  OEM  DDETC  file stock  for sale    fr EEtech ...   \n",
       "23                              Week 16 Order Inquiry   \n",
       "24  [offer]  - [OEM XS Inc] OEM XS SSD offers (16 ...   \n",
       "25                                               blah   \n",
       "26                                              Title   \n",
       "27     Amazing price/ Distributor: Server Samsung RAM   \n",
       "28                                           s2 offer   \n",
       "29                            in rely to your inquiry   \n",
       "30  [offer]  - [1st Technologies LTD] Offer 1st (P...   \n",
       "31             Offer OM (  Spectek offer for 9.4.19 )   \n",
       "32                                          B&S offer   \n",
       "33  [offer]  - [Kaan Technologies Ltd]  (09 Apr 2019)   \n",
       "34  Apple Stocks Wholesale: iPhones and iPads for ...   \n",
       "35                           Offer OM (  Micron SSD )   \n",
       "36         TAKE IT ALL BIDDING OFFER - Pan Electronic   \n",
       "37                                      Azure account   \n",
       "38                               Offer -Toshiba Cards   \n",
       "39  an offer by our vendor - quantity we can guess...   \n",
       "40  inquiry - with description, part number and pr...   \n",
       "41           inquiry - quantity brand and part number   \n",
       "42                inquiry - two items on the same row   \n",
       "43                                        Web Inquiry   \n",
       "44                                        requirement   \n",
       "45  some format we used, may have Chinese Characte...   \n",
       "46                                            Inquiry   \n",
       "47  [VIP Computer Centre Limited] require (11 Apr ...   \n",
       "48                   typical offer would be like this   \n",
       "49                                      Offer from US   \n",
       "50  [require]  - [TERABAY Co ., Ltd] requirement (...   \n",
       "51                                            [offer]   \n",
       "52                     A STANDARD FORAMT WILL BE LIKE   \n",
       "53                       MISSING PRICE - OPEN FOR BID   \n",
       "54                  model price - today's transaction   \n",
       "55                - [深圳市晟源電子有限公司] offers - 12/04/2019   \n",
       "56                                    test from Henry   \n",
       "\n",
       "                                 Content_Conversation  \\\n",
       "0                                                       \n",
       "1   [深圳市晟源電子有限公司]\\n\\n\\n\\n\\nPart number : product T...   \n",
       "2   W25Q64FWZPIGS 10000  \\n\\n\\n\\nUncertainties in ...   \n",
       "3   An email message to forward\\n\\n\\nBegin forward...   \n",
       "4                                                       \n",
       "5   <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "13                                                      \n",
       "14  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "15  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                              offer   \n",
       "21                                              0ffer   \n",
       "22                                              Offer   \n",
       "23                                                      \n",
       "24                                              Offer   \n",
       "25                                          blah blah   \n",
       "26                                     blah blah blah   \n",
       "27  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "28                                              offer   \n",
       "29  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "30                  Offer – too general, not specific   \n",
       "31                                                      \n",
       "32                                                      \n",
       "33                                                      \n",
       "34  We received offer, but sometimes we have no ex...   \n",
       "35  Offer with quantity but no  price, you need to...   \n",
       "36                                              offer   \n",
       "37  Please cehck with Kenneth, apparently Azure do...   \n",
       "38                                                      \n",
       "39  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "40  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "41  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "42  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "43  Our web site capture inquiry and notify ourselves   \n",
       "44  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "45  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "46  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "47      Only the number of pieces required are stated   \n",
       "48  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "49  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "50                                                      \n",
       "51  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "52  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "53  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "54  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "55  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "56  <!-- .rps_45ec p.x_MsoNormal, .rps_45ec li.x_M...   \n",
       "\n",
       "                                    Content_Forwarded  \n",
       "0   From: Litchi <litchi.lv@agradeflash.com> \\nSen...  \n",
       "1                                                      \n",
       "2                                                      \n",
       "3   From: BanzGames <info@banzgames.ru>\\n\\nSubject...  \n",
       "4   From: Lisa Lao <lisa@nxelectronics.com> \\nSent...  \n",
       "5                                                      \n",
       "6   From: Irene Wan <irenewan@sinobestech.com.hk> ...  \n",
       "7   -----Original Message-----\\n\\nFrom: 白菜 <251933...  \n",
       "8   From: Lisa Lao <lisa@nxelectronics.com> \\nSent...  \n",
       "9   From: Amy Guo <amyguo@nxelectronics.com> \\nSen...  \n",
       "10  From: Daniel Yu <daniel@sinobestech.com.hk> \\n...  \n",
       "11  From: Irene Wan <irenewan@sinobestech.com.hk> ...  \n",
       "12                                                     \n",
       "13  From: Winnie Wong <winniewong@nxelectronics.co...  \n",
       "14                                                     \n",
       "15                                                     \n",
       "16  From:\\nDoris Chang <dorischang@sbit.com.tw> \\n...  \n",
       "17  From: Rhoda To <Rhoda@nxelectronics.com> \\nSen...  \n",
       "18  From: Rhoda To <Rhoda@nxelectronics.com> \\nSen...  \n",
       "19  -----Original Message-----\\n\\nFrom: Irene Wan ...  \n",
       "20  From: Yuliya Grebenyuk <juliagr@neo-mid.com.ua...  \n",
       "21  From: Irene Chow <irene@nxelectronics.com> \\nS...  \n",
       "22  From: eetech <eetech@ms67.hinet.net> \\nSent: M...  \n",
       "23  From: Su Jason <jasonsuhk@gmail.com> \\nSent: T...  \n",
       "24  From: Albert Lo <albertlo@sinobestech.com.hk> ...  \n",
       "25                                                     \n",
       "26                                                     \n",
       "27                                                     \n",
       "28  From: Yoyo Chong \\nSent: Tuesday, April 9, 201...  \n",
       "29                                                     \n",
       "30  From: Irene Wan \\nSent: Tuesday, April 9, 2019...  \n",
       "31  From: Irene Wan \\nSent: Tuesday, April 9, 2019...  \n",
       "32  From:\\nDoris Chang <dorischang@sbit.com.tw> \\n...  \n",
       "33  From: albertliu@sbit.com.tw <albertliu@sbit.co...  \n",
       "34  From: Leo Jolliffe <leo@digitalcomgroup.net> \\...  \n",
       "35  From: Irene Wan \\nSent: Wednesday, April 10, 2...  \n",
       "36  From:\\nDaniel Yu \\nSent: Thursday, April 11, 2...  \n",
       "37  From: Kenneth Chung <kennethchung@sbit.com.tw>...  \n",
       "38  From: Florence Lee \\nSent: Tuesday, April 9, 2...  \n",
       "39                                                     \n",
       "40                                                     \n",
       "41                                                     \n",
       "42                                                     \n",
       "43  From: WebInquiry \\nSent: Tuesday, April 9, 201...  \n",
       "44                                                     \n",
       "45                                                     \n",
       "46                                                     \n",
       "47  From: Rhoda To \\nSent: Thursday, April 11, 201...  \n",
       "48                                                     \n",
       "49                                                     \n",
       "50  From: Lisa Lao \\nSent: Friday, April 12, 2019 ...  \n",
       "51                                                     \n",
       "52                                                     \n",
       "53                                                     \n",
       "54                                                     \n",
       "55                                                     \n",
       "56                                                     "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlook_class.pandas_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "outlookBot.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
