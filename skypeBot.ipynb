{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import time\n",
    "# create a browser instance\n",
    "from selenium import webdriver\n",
    "# emulate keyboard inputs\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# creatinga single browser instance\n",
    "import selenium.webdriver.firefox.service as service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "# WebDriverWait and EC to allow waiting for element to load on page\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# module to search for elements using xpaths\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "# exception handling\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "# quick clicking and scrolling\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "# searching of html with \"find()\"\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import os                       # file saving\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Selenium Bot Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Make sure that \"chromedriver\" and \"geckodriver\" are in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class selenium_bot():\n",
    "    \"\"\"\n",
    "    Interactable bot, that parses outlook files\n",
    "    \"\"\"\n",
    "    def __init__(self, browser, timeout, save_period, url, succesful_login_xpath):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] browser: \"Firefox\" or \"Chrome\"\n",
    "        [float] timeout: how long to wait for responses from webpage\n",
    "        [save_period] float: time in seconds to create backup of parsed data\n",
    "        [str] url: url bot starts off at\n",
    "        [str] succesful_login_xpath: xpath to indicate that page has loaded\n",
    "\n",
    "        __ Description __\n",
    "        sets up selenium bot\n",
    "        \"\"\"\n",
    "\n",
    "        self.browser = browser.lower()\n",
    "        self.timeout = timeout\n",
    "        self.url = url\n",
    "        self.succesful_login_xpath = succesful_login_xpath\n",
    "        \n",
    "        # 1 - setup browser\n",
    "        self.driver = self.__setup_chrome()\n",
    "        self.driver.maximize_window()\n",
    "\n",
    "        # 2 - load page\n",
    "        self.driver.get(self.url)\n",
    "\n",
    "        # 3- supprorting parameters for the future\n",
    "        # waiter, to wait for contents to load. call the \"waiter.until(function)\" method\n",
    "        self.WebDriverWaiter = WebDriverWait(self.driver, self.timeout)\n",
    "        self.save_period = save_period\n",
    "        \n",
    "        print(\"==> setup_browser end\\n\")\n",
    "\n",
    "    def __setup_firefox(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        open up a firefox driver\n",
    "\n",
    "        __ Returns __\n",
    "        driver handle\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - create a browser instance\n",
    "        print(\"  > Starting new Firefox server\")\n",
    "        browser = webdriver.Firefox(\n",
    "            executable_path='./geckodriver')\n",
    "\n",
    "        return browser\n",
    "\n",
    "    def __setup_chrome(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        open up a chrome driver\n",
    "\n",
    "        __ Returns __\n",
    "        driver handle\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - set capabilities\n",
    "        capabilities = {'chromeOptions':\n",
    "                        {\n",
    "                            'useAutomationExtension': False,\n",
    "                            'args': ['--disable-extensions']}\n",
    "                        }\n",
    "\n",
    "        # 2 - set options for chrome\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_experimental_option(\"prefs\", {\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True\n",
    "        })\n",
    "\n",
    "        # 3 - create a browser instance with defined options\n",
    "        print(\"  > Starting new Chrome server\")\n",
    "        browser = webdriver.Chrome(executable_path=\"./chromedriver\",\n",
    "                                   desired_capabilities=capabilities,\n",
    "                                   options=chrome_options)\n",
    "        return browser\n",
    "    \n",
    "    def supp_extract_html(self, soup, html_tags_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [soup] soup: html to extract from formatted with BeautifulSoup\n",
    "        [arr] html_tags_array: array of the form\n",
    "        \n",
    "                                    [[\"div\", {\"role\": \"option\"}], \n",
    "                                    [\"div\", {\"aria-label\": \"Reading Pane\"}], \n",
    "                                    ...]\n",
    "\n",
    "        which specifies the name (\"div\", \"span\") and attributes ({\"id\": [\"test1\", \"test2\"], \"aria-label\": \"pane\"})\n",
    "        from outer to inner tags, iteratively going down specificity levels\n",
    "\n",
    "        __ Description __\n",
    "        iterates through the supplied \"soup\" html looking for tags whose parrents match all the supplied \"html_tags\"\n",
    "\n",
    "        __ Return __\n",
    "        [htmltag1, htmltag2, htmltag3]: array of html tags that fit the search requirement\n",
    "        \"\"\"\n",
    "\n",
    "        structure_depth  = len(html_tags_array)\n",
    "        debug_counter = 0\n",
    "\n",
    "        try:\n",
    "            if(structure_depth != 1):\n",
    "                # 1 - unpack the first structure\n",
    "                current_structure = soup.find(\n",
    "                    html_tags_array[0][0], attrs=html_tags_array[0][1])\n",
    "\n",
    "                # 2 - unpack further structures until we get to the last one\n",
    "                for i in range(1, structure_depth - 1):\n",
    "                    debug_counter += 1\n",
    "                    name = html_tags_array[i][0]\n",
    "                    attrs = html_tags_array[i][1]\n",
    "                    current_structure = current_structure.find(names, attrs=attrs)\n",
    "                # 3 - extract all matches from the lowest structure\n",
    "                current_structure = current_structure.find_all(\n",
    "                    html_tags_array[-1][0], attrs=html_tags_array[-1][1])\n",
    "            else:\n",
    "                # 1 - in the special case that only one structure is specified\n",
    "                current_structure = soup.find_all(\n",
    "                    html_tags_array[0][0], attrs=html_tags_array[0][1])\n",
    "\n",
    "            return current_structure\n",
    "            \n",
    "        except AttributeError:\n",
    "            # Error when an entry is missing\n",
    "            print(\"The page does not have the html element:\\n\\t[%s, %s]\"\n",
    "                  % (html_tags_array[debug_counter], html_tags_array[debug_counter]))\n",
    "            \n",
    "            return \"\"\n",
    "        \n",
    "    def supp_extract_text(self, soup, html_tags_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [soup] soup: html to extract from formatted with BeautifulSoup\n",
    "        html_tags_array: array of the form\n",
    "        \n",
    "        [[\"div\", {\"role\": \"option\"}], \n",
    "        [\"div\", {\"aria-label\": \"Reading Pane\"}], \n",
    "        ...]\n",
    "\n",
    "        which specifies the name (\"div\", \"span\") and attributes ({\"id\": [\"test1\", \"test2\"], \"aria-label\": \"pane\"})\n",
    "        from outer to inner tags, iteratively going down specificity levels\n",
    "\n",
    "        __ Description __\n",
    "        iterates through the supplied \"soup\" html looking for tags whose parrents match all the supplied \"html_tags\"\n",
    "        then a text array is extracted from this tag\n",
    "\n",
    "        __ Return __\n",
    "        [array] matching text in the innter structure\n",
    "        \"\"\"\n",
    "\n",
    "        html_structure = self.supp_extract_html(soup, html_tags_array)\n",
    "        \n",
    "        # 1 - take all of the tags found and extract text\n",
    "        array_to_return = [i.get_text().strip() for i in html_structure]\n",
    "        \n",
    "        return array_to_return\n",
    "        \n",
    "    def supp_write_to_element(self, element_xpath, fill_value):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] element_xpath: element to look for e.g. //div[@id=|password|]\n",
    "        [str] fill_value: what to write in the form\n",
    "\n",
    "        __ Description __\n",
    "        enters the \"fill_value\" into the chosen \"element\"\n",
    "        \"\"\"\n",
    "        self.supp_wait_for_xpath(element_xpath, \"input_box\")\n",
    "        \n",
    "        element = self.driver.find_element_by_xpath(element_xpath)\n",
    "        if(element):\n",
    "            element.send_keys(fill_value)\n",
    "        else:\n",
    "            print(\"**> Element with xpath %s does not exist\" %element_xpath)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def supp_wait_for_xpath(self, xpath, description):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] xpath: xpath to wait for\n",
    "        [str] description: the object that is trying to be located. will be printed to console. \n",
    "                           \"NA\" to skip\n",
    "\n",
    "        __ Description __\n",
    "        pauses the browser until \"xpath\" is loaded on the page\n",
    "        \"\"\"\n",
    "\n",
    "        if(description != \"NA\"):\n",
    "            print(\"  > Waiting for \\\"%s\\\" to load\" %(description))\n",
    "            \n",
    "        self.WebDriverWaiter.until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, xpath)), \n",
    "            message=\"Did not find %s within the timeout time you set of %i\"%(xpath, self.timeout)\n",
    "        )\n",
    "        \n",
    "    def supp_click(self, xpath):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] xpath: xpath of object to click\n",
    "\n",
    "        __ Description __\n",
    "        clicks the element\n",
    "        \"\"\"\n",
    "        print(self.driver.find_element_by_xpath(xpath))\n",
    "        self.driver.find_element_by_xpath(xpath).click()\n",
    "        \n",
    "    def supp_load_soup(self):\n",
    "        \"\"\"\n",
    "        Loads up a soup of all the html on the visible page\n",
    "        __ Returns __\n",
    "        Soup Object to search\n",
    "        \"\"\"\n",
    "        html = self.driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        return soup\n",
    "    \n",
    "    def refresh(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        Resets variables of bot class and reload page\n",
    "        \"\"\"\n",
    "\n",
    "        self.driver.get(self.url)\n",
    "        self.supp_wait_for_xpath(self.succesful_login_xpath, \"main page\")\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        clears the pandas_out array to the initial value\n",
    "        \"\"\"\n",
    "\n",
    "        self.pandas_scraped = pd.DataFrame(columns=self.pandas_columns)\n",
    "\n",
    "    def save_data(self, file_name=\"pandas_out\", ext=\"csv\"):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] file_name: the file to save to. provide .pkl or .csv extension\n",
    "        \n",
    "        __ Description __\n",
    "        Saves data accumulated in \"pandas_out\" to output file\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1 - create output directory\n",
    "        if not os.path.exists(\"./output\"):\n",
    "            os.mkdir(\"output\")\n",
    "\n",
    "        # 2 - cut any extensions that were given by accident\n",
    "        file_name = file_name.split(\".\")[0]\n",
    "        file_name = \"./output/%s\" % (file_name)\n",
    "        \n",
    "        if(ext == \"pkl\"):\n",
    "            self.pandas_scraped.to_pickle(\"%s.pkl\" % file_name)\n",
    "        else:\n",
    "            self.pandas_scraped.to_csv(\"%s.csv\" % file_name)\n",
    "\n",
    "    def date_from_string(self, date_string):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] date_string: either day of week or \"18 May 2019\"\n",
    "\n",
    "        __ Description __\n",
    "        convert to an array numerical date values. if a weekday was supplied, find the nearest previous date\n",
    "\n",
    "        __ Return __\n",
    "        [year, month, day] date: array of the date\n",
    "        \"\"\"\n",
    "\n",
    "        weekday_list = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",\n",
    "                        \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "\n",
    "\n",
    "        if (date_string in weekday_list):\n",
    "            # 1 - set loop parameters\n",
    "            date = datetime.date.today()\n",
    "            date_shift = datetime.timedelta(days = 1)\n",
    "            date_found = False\n",
    "\n",
    "            # 2 - decrease date, until the weekday_list match\n",
    "            while(not date_found):\n",
    "                date = date - date_shift\n",
    "                day_of_the_week_long = weekday_list[date.weekday()]\n",
    "                day_of_the_week_short = weekday_list[date.weekday() + 7]\n",
    "                if((day_of_the_week_long == date_string) or (day_of_the_week_short == date_string)):\n",
    "                    date_found = True\n",
    "        else:\n",
    "            date = datetime.datetime.strptime(date_string, '%d %B %Y')\n",
    "\n",
    "        date_array = [date.year, date.month, date.day]\n",
    "        return date_array\n",
    "\n",
    "    def string_from_date(self, date_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [year, month, day] date: array of the date\n",
    "\n",
    "        __ Description __\n",
    "        converts the array to string representation \"18 May 2019\"\n",
    "\n",
    "        __ Return __\n",
    "        [str] date_string\n",
    "        \"\"\"\n",
    "\n",
    "        date = datetime.datetime(date_array[0], date_array[1], date_array[2])\n",
    "        return date.strftime(\"%d %B %Y\")    \n",
    "\n",
    "    def datetime_from_date(self, date_array):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [year, month, day] date: array of the date\n",
    "\n",
    "        __ Description __\n",
    "        converts the array to a datetime object\n",
    "\n",
    "        __ Return __\n",
    "        [datetime] datetimeObject\n",
    "        \"\"\"\n",
    "        return datetime.datetime(date_array[0], date_array[1], date_array[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Custom Wait Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class wait_for_content_forwarded():\n",
    "  \"\"\"Checking that IF there is a forwarded message, that it has been loaded\n",
    "\n",
    "  returns True if there is no forwarding message or it has been loaded\n",
    "\n",
    "  To be used in the following way:\n",
    "  formWebDriverWait.until(wait_for_content_forwarded())\n",
    "  \"\"\"\n",
    "\n",
    "  def __call__(self, driver):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    driver: the WebDriverWait.until(xxx) calls method xxx with 'driver' as the first \n",
    "    argument.\n",
    "\n",
    "    __ Description __\n",
    "    ensure that any forwarded email is fully loaded\n",
    "\n",
    "    a forwarded email has a non empty <div of forwarded email> in the following positon:\n",
    "\n",
    "    <div aria-label='Reading-Pane> ..... \n",
    "        <div>....</div>\n",
    "        <div>        <---------- div[2]\n",
    "            <div>...</div>\n",
    "            etc. etc.\n",
    "            <div of forwarded email> <----------- NON empty when there is forwarding\n",
    "            <div>...</div>        <---------- div[last()]\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    __ Return __\n",
    "    True: if forwarded email loaded\n",
    "    False: if forwaded email has NOT loaded\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1 - test if there is a forwarded section, by checking that the <div of forwarded email> is not empty\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@aria-label='Reading Pane']/div[2]/div[last()-1]/*\")\n",
    "    except NoSuchElementException:\n",
    "        #  if no email is being forwarded then we don't have to wait\n",
    "        return True\n",
    "\n",
    "    # 2 - IF there is a forwarded email, wait for the body of the forwarded email to load\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@id='Conversation.FossilizedTextBody']/div[1]\")\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        #  treurn flase if the email has not loaded yet\n",
    "        return False\n",
    "\n",
    "class wait_for_chat_update():\n",
    "  \"\"\"Checking that Skype chat has updated after scrolling has been performed\n",
    "\n",
    "  To be used in the following way:\n",
    "  formWebDriverWait.until(wait_for_chat_update(old_top_message))\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, top_message_text_old):\n",
    "      self.top_message_text_old = top_message_text_old\n",
    "      \n",
    "  def __call__(self, driver):\n",
    "    \"\"\"\n",
    "    __ Description __\n",
    "    compares the id of the top message after scrolling. \n",
    "    if scrolling has stopped (end of conversation of loading) the id will remain the same\n",
    "\n",
    "    __ Return __\n",
    "    True: if text stayed the same - need to perform a click action\n",
    "    False: if text has changed - can continue scrolling\n",
    "    \"\"\"\n",
    "\n",
    "    ########################################xpaths\n",
    "    chatBox_xpath = \"//div[@style='position: relative; display: flex; flex-direction: row; flex-grow: 1; flex-shrink: 1; overflow: hidden; align-items: stretch; background-color: rgb(255, 255, 255);']\"\n",
    "    ########################################\n",
    "    \n",
    "    chatBox = driver.find_element_by_xpath(chatBox_xpath).find_elements_by_xpath(\"//div[@role='region']\")\n",
    "\n",
    "    top_message_text_new = chatBox[0].id\n",
    "    \n",
    "    if(top_message_text_new == self.top_message_text_old):\n",
    "        # print(\"clicked and no change\")\n",
    "        return False\n",
    "    else:\n",
    "        # print(\"clicking has caused content to load\")\n",
    "        return Truec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Skype Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class skype_bot(selenium_bot):\n",
    "    \"\"\"bot to extract email content from skpye\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, browser, timeout, save_period=5,\n",
    "                 url=\"https://web.skype.com\",\n",
    "                 succesful_login_xpath=\"//div[@role='group'][@aria-label='Conversations list']\"):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] browser:                  \"Firefox\" or \"Chrome\"\n",
    "        [float] timeout:                how long to wait for tiemouts on the page\n",
    "        [str] url:                      of page to visit\n",
    "        [str] succesful_login_xpath:    xpath to indicate that page has loaded\n",
    "\n",
    "        __ Description __\n",
    "        initialisation of web driver and skype variables\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            # 1 - setup driver\n",
    "            selenium_bot.__init__(self, browser, timeout, int(save_period), url, succesful_login_xpath)\n",
    "\n",
    "            # 2 - setup skype environment\n",
    "            self.__setup()\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\n",
    "                \"**> Page failed to fully load. Increase timeout (currently %.1fs)\" % (self.timeout))\n",
    "            return\n",
    "        \n",
    "    def __setup(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        Sets up supporting objects for skype\n",
    "\n",
    "        self.pandas_scraped: ouput dataframe with keys:\n",
    "        [ \"From\", \"Date\", \"Message\"]\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 - pandas dataframe\n",
    "        self.pandas_columns = [ \"From\", \"Date\", \"Message\"]\n",
    "        self.pandas_scraped = pd.DataFrame(columns=self.pandas_columns)\n",
    "\n",
    "        self.scrape_filters_set = False\n",
    "\n",
    "    def login(self, skype_id, password):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] skype_id:         email to log on with\n",
    "        [str] password:         password\n",
    "\n",
    "        __ Description __\n",
    "        logs into skype\n",
    "        \"\"\"\n",
    "        print(\"==> login start\")\n",
    "        ########################################xpaths\n",
    "        skype_login_box_xp = \"//input[@type='email']\"\n",
    "        skype_password_box_xp = \"//input[@type='password']\"\n",
    "        skype_submit_button_xp = \"//input[@id='idSIButton9']\"\n",
    "        skype_got_it_xp = \"//div[@data-text-as-pseudo-element='Got it!']\"\n",
    "        ########################################\n",
    "        \n",
    "        # 1 - wait for email box\n",
    "        self.supp_write_to_element(skype_login_box_xp, skype_id)\n",
    "        self.driver.find_element_by_xpath(skype_submit_button_xp).click()\n",
    "        time.sleep(3)           # <---------------------------------------- need to wait for password box to come up\n",
    "        # 2 - wait for password\n",
    "        self.supp_write_to_element(skype_password_box_xp, password)\n",
    "        self.driver.find_element_by_xpath(skype_submit_button_xp).submit()\n",
    "        \n",
    "        # 3 - remove popups after page has loaded\n",
    "        self.supp_wait_for_xpath(self.succesful_login_xpath, \"page\")\n",
    "        time.sleep(2)           # <---------------------------------------- wait for the popup box to come up\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(skype_got_it_xp).click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(\"==> login end\\n\")\n",
    "\n",
    "        \n",
    "    def skype_scrollCheck_date(self, critetia, current_values):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [dict] critetia:       {\"chats_to_scrape\":      [1D-int] starting from 0,             \n",
    "                                \"date_min\":             [year,month,day] \n",
    "                                \"date_max\":             [year,month,day] \n",
    "                                \"max_number_of_stalls\": [int] before continuing}\n",
    "        [dict] current_values  {\"current_date\":         [year,month,dayy],\n",
    "                                \"current_number_of_stalls\": [int]}\n",
    "\n",
    "        __ Description __\n",
    "        checks if the filter-defined date has been reached, to determine if scrolling should continue\n",
    "\n",
    "        __ Return __\n",
    "        True if scrolling should continue\n",
    "        False if it should be stopped\n",
    "        \"\"\"\n",
    "\n",
    "        criteria_min_date = criteria['min_date']\n",
    "        current_date = current_values['current_date']\n",
    "        \n",
    "        return_val = False\n",
    "\n",
    "        if(current_values['current_number_of_stalls'] < criteria['max_number_of_stalls']):\n",
    "            # 1 - continue scrolling if date is not defined\n",
    "            if(current_date == \"Undefined\"):\n",
    "                return True\n",
    "        \n",
    "            # 2 - compare the date reached so far in the chat with the filter date\n",
    "            current_date = self.date_from_string(current_date) # convert the date from string to array\n",
    "            current_date = datetime.datetime(current_date[0], current_date[1], current_date[2]) # initialie a datetime object\n",
    "            criteria_min_date = datetime.datetime(criteria_min_date[0], criteria_min_date[1], criteria_min_date[2])\n",
    "    \n",
    "            if (criteria_min_date <= current_date):\n",
    "                return_val = True\n",
    "                \n",
    "            else:\n",
    "                print(\"\\n  > Chat scrolled past the user-defined date: %s [now at %s]\"\n",
    "                      %(criteria_min_date.strftime(\"%d %B %Y\"), current_date.strftime(\"%d %B %Y\")))\n",
    "                print(\"  > Stopping scrolling of chat\")\n",
    "        else:\n",
    "            print(\"\\n  > Chat stalled for the maximal user-defined number of scrolls: %i\"\n",
    "                  %(criteria['max_number_of_stalls']))\n",
    "            print(\"  > Stopping scrolling of chat\")\n",
    "\n",
    "        return return_val\n",
    "   \n",
    "    def skype_scrape_setup(self, chats_to_scrape, max_number_of_stalls, date_min, date_max):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [1D-int] chats_to_scrape:       chat indexes in the inbox to scrape, 0 for top chat\n",
    "        [int] max_number_of_stalls:     during scrapping, scrolling leads to occasional pauses \n",
    "                                        while the earlier content is loaded. during this time \n",
    "                                        the chat page does not change. this specifies how many \n",
    "                                        times to wait when this happens before exiting\n",
    "        [2018, 02, 01] date_min/max:    date range to scrape for each chat\n",
    "\n",
    "        __ Description __\n",
    "        Initializes the list \"self.scrape_filters\" used by the scraping functions\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"==> skype_scrape_setup start\")\n",
    "        self.criteria = {}\n",
    "\n",
    "        # 1 - chats to scrape\n",
    "        self.criteria['chats_to_scrape'] = chats_to_scrape\n",
    "\n",
    "        # 2 - number of stalls\n",
    "        print(\"  > Maximal number of stalls:\\t %i\" %(max_number_of_stalls))\n",
    "        self.criteria['max_number_of_stalls'] = max_number_of_stalls\n",
    "        \n",
    "        # 3 - set date if supplied\n",
    "        if(date_min):\n",
    "            self.criteria['date_min'] = date_min\n",
    "            print(\"  > Minimum date:\\t\\t\",\n",
    "                  datetime.datetime(date_min[0], date_min[1], date_min[2]).strftime(\"%A, %d %b %Y\"))\n",
    "        else:\n",
    "            self.criteria['date_min'] = [1, 1, 1]  # lowest date\n",
    "            print(\"  > No minimum date\")\n",
    "\n",
    "        if(date_max):\n",
    "            self.criteria['date_max'] = date_max\n",
    "            print(\"  > Maximal date:\\t\\t\",\n",
    "                  datetime.datetime(date_max[0], date_max[1], date_max[2]).strftime(\"%A, %d %b %Y\"))\n",
    "        else:\n",
    "            self.criteria['date_min'] = [8888, 1, 1]  # highest possible date\n",
    "            print(\"  > No maximal date\")\n",
    "        \n",
    "        self.scrape_filters_set = True\n",
    "\n",
    "        print(\"==> skype_scrape_setup end\\n\")\n",
    "\n",
    "    def skype_scrape(self, ext=\"csv\"):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [str] ext: format to save as. pkl or csv\n",
    "\n",
    "        __ Description __\n",
    "        Iterates through chats in Skype, saving individual date ordered (old->new) chats to files\n",
    "        \"\"\"\n",
    "        ######################################## XPATH of recent chats in the sidebar\n",
    "        chats_in_sidebar_xp = \"//div[@aria-label='Conversations list']/div/div[1]/div/div/*\"\n",
    "        chats_in_sidebar_sender_xp = \"div/div//div/div[2]/div[1]/div\"\n",
    "        ########################################\n",
    "        \n",
    "        print(\"==> skype_scrape start\")\n",
    "\n",
    "        # 1 - set default scraping filters of scraping the full first chat\n",
    "        if(not self.scrape_filters_set):\n",
    "            self.skype_scrape_setup([0], 100, None, None)\n",
    "\n",
    "        # 2 - extract all of the chats - go through the ones in the chats_to_scrape list\n",
    "        chats_to_scrape = self.criteria['chats_to_scrape']\n",
    "        chats = self.driver.find_elements_by_xpath(chats_in_sidebar_xp)\n",
    "        \n",
    "        for i, chat in enumerate(chats):\n",
    "            if(i in chats_to_scrape):\n",
    "                chats_to_scrape.remove(i)\n",
    "                \n",
    "                # 3 - get the sender\n",
    "                sender = chats[i].find_element_by_xpath(chats_in_sidebar_sender_xp).get_attribute(\"data-text-as-pseudo-element\")\n",
    "                # replace dots, @ and spaces with underscores\n",
    "                sender = sender.lower()\n",
    "                sender = re.sub(\"(\\.|@|\\s)\", \"_\", sender)\n",
    "                self.chat_info = [sender]\n",
    "                \n",
    "                # 4 - click on each chat and scrape the content\n",
    "                chats[i].click()\n",
    "                print(f\"  > Scraping Chat No.{i}:\\t {sender} \\t [{self.string_from_date(self.criteria['date_min']} - {self.string_from_date(self.criteria['date_max']}]\"\n",
    "                chat_content = self.skype_scrape_chat()\n",
    "\n",
    "                # 5 - save to file\n",
    "                self.save_data(\"skype_%s\" %(sender), ext)\n",
    "        \n",
    "        if(len(chats_to_scrape) != 0):\n",
    "            skipped_chats = re.sub(\"\\[|\\]\", \"\", str(chats_to_scrape))\n",
    "            print(\"\\t*** Did not scrape non-existing chat(s): %s ***\" %(skipped_chats))\n",
    "        print(\"==> skype_scrape end\")\n",
    "\n",
    "    def skype_scrape_chat(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        scrolls the skype chat, until the \"scrape_filters\" are satisfied e.g. reach 20th May 2018\n",
    "\n",
    "        while scrolling, extract all the messages visible in the chat, avoiding duplicates\n",
    "        \"\"\"\n",
    "\n",
    "        ################################## XPATH of chat\n",
    "        messages_xp = \"//div[@style='position: relative; display: flex; flex-direction: row; flex-grow: 1; flex-shrink: 1; overflow: hidden; align-items: stretch; background-color: rgb(255, 255, 255);']/div/div[2]/div/div/div/div/div/div/div/div/div/div/div/div/div/div[2]/div[@role='region']\"\n",
    "        ########################################\n",
    "        \n",
    "        # 1 - click on the bottom of the chat after it has loaded\n",
    "        self.supp_wait_for_xpath(messages_xp, \"at_least_one_message_in_chat\")\n",
    "        all_messages = self.driver.find_elements_by_xpath(messages_xp)\n",
    "        topMessage_ID_old = all_messages[0].id\n",
    "        ActionChains(self.driver).move_to_element(all_messages[-1]).click().perform()\n",
    "\n",
    "\n",
    "        # 2 - prepare variables for scraping\n",
    "        scraped_messages = []           # cumulative array of all the scraped_messages\n",
    "        oldest_date =  \"Undefined\"\n",
    "        continue_scroll = True\n",
    "        current_number_of_scrolls = 0\n",
    "        scroll_stall = 0            # counter to check how long scrolling has been stalled for\n",
    "        print(\"    \", end=\"\")\n",
    "        \n",
    "        while (continue_scroll):\n",
    "\n",
    "            # 3 - scroll the chat\n",
    "            ActionChains(self.driver).send_keys(Keys.PAGE_UP).perform()\n",
    "\n",
    "            # 4 - get all the scraped_messages in the current scope of the all_messages\n",
    "            all_messages = self.driver.find_elements_by_xpath(messages_xp)\n",
    "            topMessage_new = all_messages[0]\n",
    "            topMessage_ID_new = topMessage_new.id\n",
    "\n",
    "            if(topMessage_ID_new == topMessage_ID_old):\n",
    "                # 5 - if the top of the chat has not updated, jitter the chat by clicking and scrolling up and down\n",
    "                print(\"*\", end = \"\")\n",
    "                ActionChains(self.driver).move_to_element(topMessage_new).click().perform()\n",
    "                scroll_stall += 1\n",
    "                ActionChains(self.driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "                \n",
    "            else:\n",
    "                # 6 - otherwise continue scrolling\n",
    "                print(\".\", end = \"\")\n",
    "                scroll_stall = 0\n",
    "\n",
    "            # 7 - extract all scraped_messages and reverse the order so thatthey go NEW -> OLD\n",
    "            # (instead of the OLD -> NEW that top down scraping gives)\n",
    "            messages_to_add = self.skype_scrape_chat_visible()\n",
    "            messages_to_add = messages_to_add[::-1]\n",
    "\n",
    "            # 8 - store all scraped_messages with defined dates\n",
    "            for i in messages_to_add:\n",
    "                if(i[1] != \"Undefined\"):\n",
    "                    scraped_messages.append(i)\n",
    "                    oldest_date = i[1]            \n",
    "\n",
    "            # 9 - check if scroll conditions are still satisfied and repeat loop\n",
    "            continue_scroll = self.skype_scrollCheck_date(self.criteria,\n",
    "                                                          {\"current_date\": oldest_date,\n",
    "                                                           \"current_number_of_stalls\": scroll_stall})\n",
    "\n",
    "            # 10 - reset variables next loop\n",
    "            topMessage_ID_old = topMessage_ID_new\n",
    "            current_number_of_scrolls +=1\n",
    "           \n",
    "        # 11 - store the thefiltered content to pandas DataFrame\n",
    "        skype_class.skype_format_messages(scraped_messages, self.criteria)\n",
    "               \n",
    "        # 12 - notify about result of scrolling\n",
    "        filter_target_date = self.criteria['date_max']\n",
    "        # if we happen be without a defined date (early on in the scrolling), define is as today\n",
    "        if(oldest_date != \"Undefined\"):\n",
    "            oldest_date = self.date_from_string(oldest_date)\n",
    "        else:                           \n",
    "            today = datetime.datetime.today()\n",
    "            oldest_date = [today.year, today.month, today.day]\n",
    "        if (self.datetime_from_date(oldest_date) <= self.datetime_from_date(filter_target_date)):\n",
    "            print(\"  ✔ Reached target date: %s\\n\"%(self.string_from_date(filter_target_date)))\n",
    "        else:\n",
    "            print(\"  ✘ DID NOT REACH TARGET DATE: %s/%s\\n\"\n",
    "                  %(self.string_from_date(oldest_date), self.string_from_date(filter_target_date).upper()))\n",
    "\n",
    "        return scraped_messages\n",
    "        \n",
    "\n",
    "    def skype_scrape_chat_visible(self):\n",
    "        \"\"\"\n",
    "        __ Description __\n",
    "        goes through the messages visible on the screen and extracts [sender, date, message]\n",
    "\n",
    "        ⦿⦿⦿ date is of the form \"09 March 2019\" or \"Monday\" ⦿⦿⦿\n",
    "\n",
    "        __ Return __\n",
    "        [1D-(sender, date, message)]  array of tuples holding info on each message.\n",
    "        \"\"\"\n",
    "        ######################################## Attributes and names to identify messages in cconvof\n",
    "        soup_chat_message = [[\"div\", {\"role\": [\"region\", \"heading\"], \"tabindex\": re.compile(\"(-1|0)\"), \"aria-label\": re.compile(\".\")}]]\n",
    "        ########################################\n",
    "\n",
    "        \n",
    "        # 1 - get html of the page and look for messages with beautiful soup\n",
    "        soup = self.supp_load_soup()\n",
    "        chatContent = self.supp_extract_html(soup, soup_chat_message)\n",
    "\n",
    "        messages = []\n",
    "        date_current = \"Undefined\"\n",
    "        \n",
    "        for i in chatContent:\n",
    "            # 2 - extract contents of the messages\n",
    "            message_content = i[\"aria-label\"]\n",
    "\n",
    "            # a - date extraction\n",
    "            date = re.match(\n",
    "                re.compile(\"((\\d{2}\\s(January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4})|(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday))\"),\n",
    "                            message_content)\n",
    "            if(date):\n",
    "                date = date.group(1)\n",
    "                date_current = date\n",
    "\n",
    "            # b - sender extraction\n",
    "            #     sender comes before the main part of the message e.g. \"YAU, shall we go ....\"\n",
    "            sender = re.search(re.compile(\"(^\\w+(\\s\\w+)?)(,)\"), message_content)\n",
    "            if(sender):\n",
    "                sender = sender.group(1)\n",
    "            else:\n",
    "                sender = None\n",
    "\n",
    "            # c - message: comes after the sender with a comma and before the time sent e.g. \"yau, SHALL WE GO..., sent at 18:00\"\n",
    "            message = re.search(re.compile(\"(^\\w+(\\s\\w+)?,)(.*)(, sent at \\d{2}:\\d{2})\"), message_content)\n",
    "            if(message):\n",
    "                message = message.group(3)\n",
    "            else:\n",
    "                message = None\n",
    "\n",
    "            # 2 - store the message if it was NOT a date (e.g. 09 March 2019)\n",
    "            if((not date) and message):\n",
    "                messages.append((sender, date_current, message))\n",
    "\n",
    "        return messages\n",
    "\n",
    "    def skype_format_messages(self, messages_to_format, critetia):\n",
    "        \"\"\"\n",
    "        __ Parameters __\n",
    "        [arr] messages_to_format:   list of tuples of the form\n",
    "                                    (sender, dateString, message)\n",
    "\n",
    "        __ Description __\n",
    "        the list of messages is scanned and:\n",
    "        - messages with an unassigned dates (\"Undefined\") are given a date\n",
    "        - duplicate messages are removed\n",
    "        - messages newer than a certain values are removed\n",
    "\n",
    "        __ Return __\n",
    "        [pd.DataFrame] pandas_out: dataFrame with all the messages_to_format\n",
    "        \"\"\"\n",
    "\n",
    "        message_to_format = messages_to_format[::-1] # revese the message order, so that oldest (with defined date) are on top\n",
    "        self.reset()\n",
    "\n",
    "        # setup dates\n",
    "        date_min = criteria['min_date']\n",
    "        date_min = datetime.datetime(date_min[0], date_min[1], date_min[2])\n",
    "        date_max = criteria['max_date']\n",
    "        date_max = datetime.datetime(date_max[0], date_max[1], date_max[2])\n",
    "        running_date = \"Undefined\" # date that keeps track of where we are in the mssages\n",
    "        \n",
    "        # 1 - iterate the messages, resolving any dates that were not extracted during scrolling\n",
    "        for i in messages_to_format:\n",
    "\n",
    "            date = i[1]\n",
    "\n",
    "            if(date == \"Undefined\"):\n",
    "                # a - if a date was not defined, look at the previously defined date\n",
    "                date = running_date\n",
    "\n",
    "            else:\n",
    "                # b - convert date to [year, month, day]\n",
    "                date = self.date_from_string(date)\n",
    "                running_date = date # store the running date, so that further dates can be infered from it\n",
    "                \n",
    "            # 2 - write messages with defined dates that fall in the defined filter region\n",
    "            if(date != \"Undefined\"):\n",
    "\n",
    "                date = self.datetime_from_date(date)\n",
    "                \n",
    "                if((date >= date_min) and (date <= date_max)):\n",
    "                    date_string = date.strftime(\"%d %B %Y\")\n",
    "                    # 2 - store the message in a dataframe\n",
    "                    message_to_store = {\"From\": i[0],\n",
    "                                        \"Date\": date_string,\n",
    "                                        \"Message\": i[2]}\n",
    "\n",
    "                    self.pandas_scraped = self.pandas_scraped.append(message_to_store, ignore_index=True)\n",
    "\n",
    "        # 3 - remove duplicate entries due to scrolling overlap\n",
    "        self.pandas_scraped = self.pandas_scraped.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Skype running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> setup_browser start\n",
      "  > Starting new Chrome server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> setup_browser end\n",
      "\n",
      "==> login start\n",
      "  > Waiting for \"input_box\" to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Waiting for \"input_box\" to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Waiting for \"page\" to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> login end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########################################\n",
    "skype_id = \"ilya.antonov24@ntlworld.com\"\n",
    "password = \"east-india-company\"\n",
    "timeout = 10                      # seconds to wait for page elements to load\n",
    "browser = \"chrome\"                # firefox of chrome\n",
    "########################################\n",
    "########################################\n",
    "skype_class = skype_bot(browser, timeout)\n",
    "skype_class.login(skype_id, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> skype_scrape_setup start\n",
      "  > Maximal number of stalls:\t 14\n",
      "  > Minimum date:\t\t Friday, 01 Feb 2019\n",
      "  > Maximal date:\t\t Saturday, 20 Apr 2019\n",
      "==> skype_scrape_setup end\n",
      "\n",
      "==> skype_scrape start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Scraping Chat No.0:\t maria__merkulova \t [01 February 2019 - 20 April 2019]\n",
      "  > Waiting for \"at_least_one_message_in_chat\" to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    **"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  > Chat scrolled past the user-defined date: 01 February 2019 [now at 27 December 2018]\n",
      "  > Stopping scrolling of chat\n",
      "  ✔ Reached target date: 01 February 2019\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Scraping Chat No.1:\t yau_bryan \t [01 February 2019 - 20 April 2019]\n",
      "  > Waiting for \"at_least_one_message_in_chat\" to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    *"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "  > Chat stalled for the maximal user-defined number of scrolls: 14\n",
      "  > Stopping scrolling of chat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✘ DID NOT REACH TARGET DATE: 05 February 2019/01 FEBRUARY 2019\n",
      "\n",
      "==> skype_scrape end\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########################################\n",
    "chats_to_extract = [0,1]#[0, 1, 2, 4, 6, 10]    # chats to extract, given by index\n",
    "max_number_of_stalls = 14\n",
    "min_date = [2019, 2, 1]        # either None or [2018, 1, 1]\n",
    "max_date = [2019, 4, 20]        # either None or [2018, 1, 1]\n",
    "########################################\n",
    "########################################\n",
    "skype_class.skype_scrape_setup(chats_to_extract, max_number_of_stalls, min_date, max_date)\n",
    "skype_class.skype_scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "skypeBot.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
